{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd05a49a43dbdc81075b29e5ecd09eb50057293e35818ee42103cfdfdfc359e5918",
   "display_name": "Python 3.6.12 64-bit ('tensorflow2_x': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "WIDTH = 848\n",
    "HEIGHT = 480\n",
    "FPS = 60\n",
    "THRESHOLD_MAX = 0.6#これより近い距離の画素を無視する\n",
    "THRESHOLD_MIN = 1.0#これより遠い距離の画素を無視する\n",
    "\n",
    "def red_detect(img):\n",
    "    # HSV色空間に変換\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 赤色のHSVの値域1\n",
    "    hsv_min = np.array([0,127,0])\n",
    "    hsv_max = np.array([30,255,255])\n",
    "    mask1 = cv2.inRange(hsv, hsv_min, hsv_max)\n",
    "\n",
    "    # 赤色のHSVの値域2\n",
    "    hsv_min = np.array([150,127,0])\n",
    "    hsv_max = np.array([179,255,255])\n",
    "    mask2 = cv2.inRange(hsv, hsv_min, hsv_max)\n",
    "    \n",
    "    return mask2\n",
    "\n",
    "# ブロブ解析\n",
    "def analysis_blob(binary_img):\n",
    "    # 2値画像のラベリング処理\n",
    "    label = cv2.connectedComponentsWithStats(binary_img)\n",
    "\n",
    "    # ブロブ情報を項目別に抽出\n",
    "    nlabels = label[0] - 1\n",
    "    data = np.delete(label[2], 0, 0)\n",
    "    center = np.delete(label[3], 0, 0)\n",
    "    \n",
    "    if np.any(data)==True:\n",
    "        # ブロブ面積最大のインデックス\n",
    "        max_index = np.argmax(data[:, 3])\n",
    "\n",
    "        # 面積最大ブロブの情報格納用\n",
    "        maxblob = {}\n",
    "\n",
    "        # 面積最大ブロブの各種情報を取得\n",
    "        maxblob[\"upper_left\"] = (data[:, 0][max_index], data[:, 1][max_index]) # 左上座標\n",
    "        maxblob[\"width\"] = data[:, 2][max_index]  # 幅\n",
    "        maxblob[\"height\"] = data[:, 3][max_index]  # 高さ\n",
    "        maxblob[\"area\"] = data[:, 4][max_index]   # 面積\n",
    "        maxblob[\"center\"] = center[max_index]  # 中心座標\n",
    "    else:\n",
    "        maxblob=0\n",
    "    return maxblob\n",
    "\n",
    "def main():\n",
    "\n",
    "    # ストリーム(Depth/Color)の設定\n",
    "    config = rs.config()\n",
    "    config.enable_stream(rs.stream.color, WIDTH, HEIGHT, rs.format.bgr8, FPS)\n",
    "    config.enable_stream(rs.stream.depth, WIDTH, HEIGHT, rs.format.z16, FPS)\n",
    "\n",
    "    # ストリーミング開始\n",
    "    pipeline = rs.pipeline()\n",
    "    profile = pipeline.start(config)\n",
    "\n",
    "    # Alignオブジェクト生成\n",
    "    align_to = rs.stream.color\n",
    "    align = rs.align(align_to)\n",
    "\n",
    "    #画像に合わせたdepth指定の値算出\n",
    "    depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "    max_dist = THRESHOLD_MAX/depth_scale\n",
    "    min_dist = THRESHOLD_MIN/depth_scale\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            #フレーム待ち(Color & Depth)\n",
    "            frames = pipeline.wait_for_frames()\n",
    "\n",
    "            #画角補正した情報フレーム取得\n",
    "            aligned_frames = align.process(frames)\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "            depth_frame = aligned_frames.get_depth_frame()\n",
    "            if not depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            #RGB画像をnumpy arrayに\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            #depth画像をnumpy arrayに\n",
    "            # depth_color_frame = rs.colorizer().colorize(depth_frame)\n",
    "            # depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "\n",
    "            #指定距離最大・最小以上をカットしたdepth画像\n",
    "            depth_image = np.asanyarray(depth_frame.get_data())\n",
    "            depth_filterd_image = ((min_dist < depth_image) ^ (max_dist < depth_image)) * depth_image\n",
    "            # depth_gray_filtered_image = (depth_filterd_image * 255.0 / m)\n",
    "\n",
    "            #指定距離最大・最小以上をカットしたRGB画像\n",
    "            color_filtered_image = (depth_filterd_image.reshape((HEIGHT, WIDTH, 1)) > 0) * color_image\n",
    "\n",
    "\n",
    "\n",
    "            # カラートラッキング（赤色）\n",
    "            mask = red_detect(color_filtered_image)\n",
    "\n",
    "            # マスク画像をブロブ解析（面積最大のブロブ情報を取得）\n",
    "            target = analysis_blob(mask)\n",
    "\n",
    "            if not target==0:\n",
    "                # 面積最大ブロブの中心座標を取得\n",
    "                center_x = int(target[\"center\"][0])\n",
    "                center_y = int(target[\"center\"][1])\n",
    "\n",
    "                # フレームに面積最大ブロブの中心周囲を円で描く\n",
    "                cv2.circle(color_filtered_image, (center_x, center_y), 30, (0, 200, 0),\n",
    "                        thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "                depth = depth_frame.get_distance(center_x, center_y)\n",
    "\n",
    "                # ウィンドウ表示\n",
    "                cv2.putText(color_filtered_image, str(depth)+\"m\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), thickness=2)\n",
    "                cv2.imshow(\"Frame\", color_filtered_image)\n",
    "                cv2.imshow(\"Mask\", mask)\n",
    "            \n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # When everything done, release the capture\n",
    "                break\n",
    "    finally:\n",
    "        pipeline.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ]
}